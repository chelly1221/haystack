import asyncio
import uuid
from typing import Dict, List, Optional, Set
from datetime import datetime, timedelta
import threading
import logging
from enum import Enum
import sqlite3
import json
import os
from contextlib import contextmanager

class TaskStatus(Enum):
    UPLOADING = "uploading"
    QUEUED = "queued"
    PROCESSING = "processing"
    COMPLETED = "completed"
    FAILED = "failed"

class TaskManager:
    def __init__(self, db_path: str = "./data/tasks.db"):
        self.db_path = db_path
        self.processing_queue = asyncio.Queue()
        self.worker_task = None
        
        # Create data directory if not exists
        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)
        
        # Initialize database
        self._init_db()
        
        # Start cleanup task
        asyncio.create_task(self._periodic_cleanup())
        
        # Start stale task checker
        asyncio.create_task(self._check_stale_tasks())
    
    def _init_db(self):
        """Initialize SQLite database"""
        with self._get_db() as conn:
            conn.execute('''
                CREATE TABLE IF NOT EXISTS tasks (
                    id TEXT PRIMARY KEY,
                    filename TEXT NOT NULL,
                    sosok TEXT NOT NULL,
                    site TEXT NOT NULL,
                    status TEXT NOT NULL,
                    progress INTEGER DEFAULT 0,
                    message TEXT,
                    created_at TIMESTAMP NOT NULL,
                    updated_at TIMESTAMP NOT NULL,
                    completed_at TIMESTAMP,
                    result TEXT,
                    error TEXT,
                    file_path TEXT,
                    total_pages INTEGER DEFAULT 0,
                    processed_pages INTEGER DEFAULT 0,
                    is_dismissed BOOLEAN DEFAULT 0
                )
            ''')
            
            # Create indexes for better performance
            conn.execute('CREATE INDEX IF NOT EXISTS idx_sosok_site ON tasks(sosok, site)')
            conn.execute('CREATE INDEX IF NOT EXISTS idx_created_at ON tasks(created_at)')
            conn.execute('CREATE INDEX IF NOT EXISTS idx_status ON tasks(status)')
            conn.execute('CREATE INDEX IF NOT EXISTS idx_dismissed ON tasks(is_dismissed)')
            conn.execute('CREATE INDEX IF NOT EXISTS idx_updated_at ON tasks(updated_at)')
            
            conn.commit()
    
    @contextmanager
    def _get_db(self):
        """Get database connection with proper handling"""
        conn = sqlite3.connect(self.db_path, timeout=30.0)
        conn.row_factory = sqlite3.Row
        try:
            yield conn
        finally:
            conn.close()
    
    def create_task(self, filename: str, sosok: str, site: str) -> str:
        """ìƒˆ ì‘ì—… ìƒì„±"""
        task_id = str(uuid.uuid4())
        now = datetime.now()
        
        with self._get_db() as conn:
            conn.execute('''
                INSERT INTO tasks (
                    id, filename, sosok, site, status, progress, message,
                    created_at, updated_at, is_dismissed
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                task_id, filename, sosok, site, TaskStatus.UPLOADING.value,
                0, "íŒŒì¼ ì „ì†¡ ì¤‘...", now, now, 0
            ))
            conn.commit()
        
        logging.info(f"ğŸ“‹ Created task {task_id} for {filename}")
        return task_id
    
    def update_task_status(self, task_id: str, status: TaskStatus, 
                          progress: int = None, message: str = None,
                          total_pages: int = None, processed_pages: int = None):
        """ì‘ì—… ìƒíƒœ ì—…ë°ì´íŠ¸"""
        with self._get_db() as conn:
            # Build update query dynamically
            updates = ['status = ?', 'updated_at = ?']
            params = [status.value, datetime.now()]
            
            if progress is not None:
                updates.append('progress = ?')
                params.append(progress)
            
            if message is not None:
                updates.append('message = ?')
                params.append(message)
            
            if total_pages is not None:
                updates.append('total_pages = ?')
                params.append(total_pages)
            
            if processed_pages is not None:
                updates.append('processed_pages = ?')
                params.append(processed_pages)
            
            params.append(task_id)
            
            query = f"UPDATE tasks SET {', '.join(updates)} WHERE id = ?"
            conn.execute(query, params)
            conn.commit()
        
        logging.info(f"ğŸ“Š Updated task {task_id}: {status.value} - {progress}%")
    
    def set_task_file_path(self, task_id: str, file_path: str):
        """ì‘ì—…ì— íŒŒì¼ ê²½ë¡œ ì„¤ì •"""
        with self._get_db() as conn:
            conn.execute(
                "UPDATE tasks SET file_path = ?, updated_at = ? WHERE id = ?",
                (file_path, datetime.now(), task_id)
            )
            conn.commit()
    
    def complete_task(self, task_id: str, result: dict):
        """ì‘ì—… ì™„ë£Œ ì²˜ë¦¬"""
        now = datetime.now()
        with self._get_db() as conn:
            conn.execute('''
                UPDATE tasks 
                SET status = ?, progress = ?, message = ?, result = ?, 
                    updated_at = ?, completed_at = ?
                WHERE id = ?
            ''', (
                TaskStatus.COMPLETED.value, 100, "ì²˜ë¦¬ ì™„ë£Œ",
                json.dumps(result), now, now, task_id
            ))
            conn.commit()
        
        logging.info(f"âœ… Completed task {task_id}")
    
    def fail_task(self, task_id: str, error: str):
        """ì‘ì—… ì‹¤íŒ¨ ì²˜ë¦¬"""
        now = datetime.now()
        with self._get_db() as conn:
            conn.execute('''
                UPDATE tasks 
                SET status = ?, message = ?, error = ?, 
                    updated_at = ?, completed_at = ?
                WHERE id = ?
            ''', (
                TaskStatus.FAILED.value, "ì²˜ë¦¬ ì‹¤íŒ¨", error,
                now, now, task_id
            ))
            conn.commit()
        
        logging.error(f"âŒ Failed task {task_id}: {error}")
    
    def dismiss_task(self, task_id: str):
        """í´ë¼ì´ì–¸íŠ¸ì—ì„œ ì‘ì—… ì œê±° (UIì—ì„œë§Œ ìˆ¨ê¹€)"""
        with self._get_db() as conn:
            result = conn.execute(
                "UPDATE tasks SET is_dismissed = 1, updated_at = ? WHERE id = ?",
                (datetime.now(), task_id)
            )
            conn.commit()
            updated_count = result.rowcount
        
        logging.info(f"ğŸ—‘ï¸ Dismissed task {task_id} (updated: {updated_count})")
    
    def dismiss_completed_tasks(self, sosok: str, site: str):
        """íŠ¹ì • í˜„ì¥ì˜ ì™„ë£Œ/ì‹¤íŒ¨ ì‘ì—… ëª¨ë‘ ì œê±°"""
        with self._get_db() as conn:
            # ë¡œê·¸ë¥¼ ìœ„í•´ ë¨¼ì € ì¹´ìš´íŠ¸
            cursor = conn.execute('''
                SELECT COUNT(*) as count FROM tasks 
                WHERE sosok = ? AND site = ? 
                AND status IN (?, ?)
                AND is_dismissed = 0
            ''', (
                sosok, site,
                TaskStatus.COMPLETED.value, TaskStatus.FAILED.value
            ))
            count_before = cursor.fetchone()['count']
            
            # ì—…ë°ì´íŠ¸ ì‹¤í–‰
            result = conn.execute('''
                UPDATE tasks 
                SET is_dismissed = 1, updated_at = ?
                WHERE sosok = ? AND site = ? 
                AND status IN (?, ?)
                AND is_dismissed = 0
            ''', (
                datetime.now(), sosok, site,
                TaskStatus.COMPLETED.value, TaskStatus.FAILED.value
            ))
            conn.commit()
            dismissed_count = result.rowcount
        
        logging.info(f"ğŸ—‘ï¸ Dismissed {dismissed_count} completed tasks for {sosok}/{site} (found {count_before} before update)")
    
    def get_tasks_by_site(self, sosok: str, site: str) -> List[Dict]:
        """íŠ¹ì • í˜„ì¥ì˜ ì‘ì—… ëª©ë¡ ì¡°íšŒ (ì œê±°ëœ ì‘ì—… ì œì™¸)"""
        cutoff_time = datetime.now() - timedelta(hours=24)
        
        # ë¨¼ì € ì˜¤ë˜ëœ ì§„í–‰ ì¤‘ì¸ ì‘ì—…ì„ ì •ë¦¬
        self._cleanup_stale_tasks()
        
        with self._get_db() as conn:
            cursor = conn.execute('''
                SELECT * FROM tasks
                WHERE sosok = ? AND site = ?
                AND created_at > ?
                AND is_dismissed = 0
                ORDER BY created_at DESC
            ''', (sosok, site, cutoff_time))
            
            tasks = []
            for row in cursor:
                task_dict = dict(row)
                
                # Parse JSON fields
                if task_dict.get('result'):
                    try:
                        task_dict['result'] = json.loads(task_dict['result'])
                    except:
                        pass
                
                # Convert timestamps to ISO format
                for field in ['created_at', 'updated_at', 'completed_at']:
                    if task_dict.get(field):
                        try:
                            # SQLite stores as string, parse and format
                            if isinstance(task_dict[field], str):
                                dt = datetime.fromisoformat(task_dict[field])
                            else:
                                dt = task_dict[field]
                            task_dict[field] = dt.isoformat()
                        except:
                            pass
                
                # Ensure is_dismissed is boolean
                task_dict['is_dismissed'] = bool(task_dict.get('is_dismissed', 0))
                
                tasks.append(task_dict)
        
        logging.info(f"ğŸ“‹ Retrieved {len(tasks)} non-dismissed tasks for {sosok}/{site}")
        return tasks
    
    def get_task(self, task_id: str) -> Optional[Dict]:
        """íŠ¹ì • ì‘ì—… ì¡°íšŒ"""
        with self._get_db() as conn:
            cursor = conn.execute(
                "SELECT * FROM tasks WHERE id = ?",
                (task_id,)
            )
            row = cursor.fetchone()
            
            if row:
                task_dict = dict(row)
                
                # Parse JSON fields
                if task_dict.get('result'):
                    try:
                        task_dict['result'] = json.loads(task_dict['result'])
                    except:
                        pass
                
                # Convert timestamps to ISO format
                for field in ['created_at', 'updated_at', 'completed_at']:
                    if task_dict.get(field):
                        try:
                            if isinstance(task_dict[field], str):
                                dt = datetime.fromisoformat(task_dict[field])
                            else:
                                dt = task_dict[field]
                            task_dict[field] = dt.isoformat()
                        except:
                            pass
                
                # Ensure is_dismissed is boolean
                task_dict['is_dismissed'] = bool(task_dict.get('is_dismissed', 0))
                
                return task_dict
        
        return None
    
    def get_task_file_path(self, task_id: str) -> Optional[str]:
        """ì‘ì—…ì˜ íŒŒì¼ ê²½ë¡œ ì¡°íšŒ"""
        with self._get_db() as conn:
            cursor = conn.execute(
                "SELECT file_path FROM tasks WHERE id = ?",
                (task_id,)
            )
            row = cursor.fetchone()
            return row['file_path'] if row else None
    
    def _cleanup_stale_tasks(self):
        """ì˜¤ë˜ëœ ì§„í–‰ ì¤‘ì¸ ì‘ì—…ì„ ì‹¤íŒ¨ë¡œ ì²˜ë¦¬"""
        # 10ë¶„ ì´ìƒ ì—…ë°ì´íŠ¸ë˜ì§€ ì•Šì€ ì§„í–‰ ì¤‘ì¸ ì‘ì—…ì„ ì°¾ìŒ
        stale_threshold = datetime.now() - timedelta(minutes=10)
        
        with self._get_db() as conn:
            # ì˜¤ë˜ëœ ì§„í–‰ ì¤‘ì¸ ì‘ì—… ì°¾ê¸°
            cursor = conn.execute('''
                SELECT id, filename, status, updated_at FROM tasks
                WHERE status IN (?, ?, ?)
                AND updated_at < ?
                AND is_dismissed = 0
            ''', (
                TaskStatus.UPLOADING.value,
                TaskStatus.QUEUED.value,
                TaskStatus.PROCESSING.value,
                stale_threshold
            ))
            
            stale_tasks = cursor.fetchall()
            
            if stale_tasks:
                logging.warning(f"âš ï¸ Found {len(stale_tasks)} stale tasks")
                
                for task in stale_tasks:
                    task_id = task['id']
                    filename = task['filename']
                    status = task['status']
                    
                    logging.warning(f"âš ï¸ Marking stale task as failed: {task_id} ({filename}) - was {status}")
                    
                    # ì‘ì—…ì„ ì‹¤íŒ¨ë¡œ í‘œì‹œ
                    now = datetime.now()
                    conn.execute('''
                        UPDATE tasks 
                        SET status = ?, message = ?, error = ?, 
                            updated_at = ?, completed_at = ?
                        WHERE id = ?
                    ''', (
                        TaskStatus.FAILED.value, 
                        "ì²˜ë¦¬ ì‹œê°„ ì´ˆê³¼",
                        f"ì‘ì—…ì´ 10ë¶„ ì´ìƒ ì§„í–‰ë˜ì§€ ì•Šì•„ ìë™ìœ¼ë¡œ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤. (ë§ˆì§€ë§‰ ìƒíƒœ: {status})",
                        now, now, task_id
                    ))
                    
                    # ê´€ë ¨ íŒŒì¼ ì •ë¦¬
                    file_path = self.get_task_file_path(task_id)
                    if file_path and os.path.exists(file_path):
                        try:
                            os.remove(file_path)
                            meta_path = file_path + ".meta.json"
                            if os.path.exists(meta_path):
                                os.remove(meta_path)
                            logging.info(f"ğŸ—‘ï¸ Cleaned up files for stale task {task_id}")
                        except Exception as e:
                            logging.warning(f"Failed to clean up files for stale task {task_id}: {e}")
                
                conn.commit()
                logging.info(f"âœ… Marked {len(stale_tasks)} stale tasks as failed")
    
    def cleanup_old_tasks(self):
        """ì˜¤ë˜ëœ ì‘ì—… ì •ë¦¬ (24ì‹œê°„ ì´ìƒ)"""
        cutoff_time = datetime.now() - timedelta(hours=24)
        
        with self._get_db() as conn:
            # ë¨¼ì € íŒŒì¼ ê²½ë¡œë¥¼ ê°€ì ¸ì™€ì„œ íŒŒì¼ ì‚­ì œ
            cursor = conn.execute(
                "SELECT file_path FROM tasks WHERE created_at < ? AND file_path IS NOT NULL",
                (cutoff_time,)
            )
            
            file_paths = []
            for row in cursor:
                if row['file_path']:
                    file_paths.append(row['file_path'])
            
            # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì‚­ì œ
            result = conn.execute(
                "DELETE FROM tasks WHERE created_at < ?",
                (cutoff_time,)
            )
            conn.commit()
            deleted_count = result.rowcount
        
        # íŒŒì¼ ì‚­ì œ
        for file_path in file_paths:
            try:
                if os.path.exists(file_path):
                    os.remove(file_path)
                meta_path = file_path + ".meta.json"
                if os.path.exists(meta_path):
                    os.remove(meta_path)
            except Exception as e:
                logging.warning(f"Failed to delete file {file_path}: {e}")
        
        if deleted_count > 0:
            logging.info(f"ğŸ§¹ Cleaned up {deleted_count} old tasks")
    
    async def enqueue_for_processing(self, task_id: str):
        """ì²˜ë¦¬ íì— ì‘ì—… ì¶”ê°€"""
        await self.processing_queue.put(task_id)
        self.update_task_status(task_id, TaskStatus.QUEUED, message="ì²˜ë¦¬ ëŒ€ê¸° ì¤‘...")
    
    async def _check_stale_tasks(self):
        """ì£¼ê¸°ì ìœ¼ë¡œ ì˜¤ë˜ëœ ì‘ì—… í™•ì¸ ë° ì •ë¦¬"""
        while True:
            await asyncio.sleep(60)  # 1ë¶„ë§ˆë‹¤ í™•ì¸
            try:
                self._cleanup_stale_tasks()
            except Exception as e:
                logging.error(f"Error checking stale tasks: {e}")
    
    async def _periodic_cleanup(self):
        """ì£¼ê¸°ì ì¸ ì •ë¦¬ ì‘ì—…"""
        while True:
            await asyncio.sleep(3600)  # 1ì‹œê°„ë§ˆë‹¤
            try:
                self.cleanup_old_tasks()
            except Exception as e:
                logging.error(f"Error during cleanup: {e}")
    
    def cancel_task(self, task_id: str) -> bool:
        """ì‘ì—… ì·¨ì†Œ"""
        with self._get_db() as conn:
            # ì‘ì—… ìƒíƒœ í™•ì¸
            cursor = conn.execute(
                "SELECT status, file_path FROM tasks WHERE id = ?",
                (task_id,)
            )
            row = cursor.fetchone()
            
            if not row:
                return False
            
            status = row['status']
            file_path = row['file_path']
            
            # uploading ë˜ëŠ” queued ìƒíƒœë§Œ ì·¨ì†Œ ê°€ëŠ¥
            if status not in [TaskStatus.UPLOADING.value, TaskStatus.QUEUED.value]:
                logging.warning(f"Cannot cancel task {task_id} with status {status}")
                return False
            
            # ì‘ì—…ì„ ì‹¤íŒ¨ë¡œ í‘œì‹œ
            now = datetime.now()
            conn.execute('''
                UPDATE tasks 
                SET status = ?, message = ?, error = ?, 
                    updated_at = ?, completed_at = ?
                WHERE id = ?
            ''', (
                TaskStatus.FAILED.value, 
                "ì‚¬ìš©ìê°€ ì·¨ì†Œí•¨",
                "ì‚¬ìš©ì ìš”ì²­ìœ¼ë¡œ ì‘ì—…ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.",
                now, now, task_id
            ))
            conn.commit()
            
            # ê´€ë ¨ íŒŒì¼ ì •ë¦¬
            if file_path and os.path.exists(file_path):
                try:
                    os.remove(file_path)
                    meta_path = file_path + ".meta.json"
                    if os.path.exists(meta_path):
                        os.remove(meta_path)
                    logging.info(f"ğŸ—‘ï¸ Cleaned up files for cancelled task {task_id}")
                except Exception as e:
                    logging.warning(f"Failed to clean up files for cancelled task {task_id}: {e}")
            
            logging.info(f"ğŸš« Cancelled task {task_id}")
            return True

# ì „ì—­ TaskManager ì¸ìŠ¤í„´ìŠ¤
task_manager = TaskManager()